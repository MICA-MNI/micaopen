# Structural MRI analysis pipeline

This directory contains scripts and instructions for processing and analyzing amygdala data from native space quantiative T1 (qT1) images. Overall, these steps translate methods developed in histology to in vivo MRI.

## Prerequisites

- qT1 scans of 10 healthy subjects from the MICA-PNI dataset (Cabalo et al. 2024). Transform files from each participant's native space to MNI space can be generated using micapipe (Rodriguez-Cruces, Royer, et al. 2022)
- Required software: Python v3.7, ITK-snap v3.8

## Steps

### Segment amygdala from quantitative T1 scans

1. **Automated segmentation fo the amygdala:** Amygdala masks were generated using [VolBrain](https://volbrain.net/) (Manjón and Coupé, 2016).

- **Input:** 
  - Quantitative T1 map or T1-weighted image in the same space as qT1 image
- **Output:** 
  - Subcortical segmentation

Once the subcortical segmentation is generated, only the label for the amaygdala was retained and the resulting mask was binarized. If necessary, borders of the amygdala mask can be manually quality controlled using software such as ITK-Snap (Yushkevich et al. 2016) 

2. **Crop amygdala volumes**: Whole-brain volumes (structural image and amygdala mask) were cropped to only retain the amygdala for computational efficiency in further analyses. 

### Generate radiomics features

3. **Feature extraction:** Radiomics features of the amygdala can be generated for all moments and kernel sizes.

- **Input:** 
  - Amygdala mask
  - Cropped amygdala volume (from qT1 scan)
- **Output:** 
  - Feature bank (n=20, 4 moments x 5 kernel sizes, for each participant)

**Script:** `6.test_radiomics.ipynb`

### Clean radiomics features for post-processing

4. **Clean radiomic feature outputs:** After generating features with pyradiomics, some feature outputs may have different sizes relative to the orginal input volume (due to padding). All volumes should be cropped to a consistent size.
5. **Create feature bank matrix:** Put all features into a PANDAS dataframe of all the moments (feature bank).

- **Input:** 
  - Feature volumes
- **Output:** 
  - .csv file of feature bank, for each participant

**Script:** `8.crop_featurebank.ipynb`

### Generate UMAP projections

6. **Generate individualized UMAP space:** With the feature bank, we can then generate UMAP projections from each participant's feature bank data and save all embeddings as .csv files.

- **Input:** 
  - Feature bank
- **Output:** 
  - UMAP embeddings of feature bank (2 components)

**Script:** `9.Umap_.ipynb`

### UMAP projection volumetric conversion and alignment

7. **Reshape U1 and U2 vectors:** Each UMAP component is independently reshaped to a volumetric representation aligned to each participant's native qT1 space. 
8. **Register U1 and U2 maps to MNI152 space:** We leverage existing transforms generated by micapipe to register U1 and U2 volumetric maps to MNI152 space. 
9. **Correlate aligned maps with anatomical coordinates:** Subject-specific as well as BigBrain UMAP components are spatially correlated to anatomical coordinate spaces (x,y, and z coordinates) and visualized using radar plots. 

- **Input:** 
  - Correlation table
- **Output:** 
  - Correlation radar plot

**Script:** `13.radarplots.ipynb`

### Variogram matching test
Apply variogram matching test to account for spatial autocorrelation in correlating U1 and U2 with all three coordinate axes, for all 10 subjects.

- **Input:** 
  - Amygdala Mask
  - UMAP embeddings
- **Output:** 
  - Histogram and p-values of variogram null model

**Script:** `14.variograms-mni152.ipynb`
